{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen3-TTS 파인튜닝 - Marlene Voice\n",
    "\n",
    "**테스트 목표:** v6 vs C 설정 비교 + 제로샷 비교\n",
    "\n",
    "| 모델 | attn | lr | batch |\n",
    "|------|------|-----|-------|\n",
    "| v6 | flash | 1e-6 | 8 |\n",
    "| C | flash | 1e-6 | 2 |\n",
    "| 제로샷 | - | - | - |\n",
    "\n",
    "**사전 준비:** Google Drive에 `marlene_tts_data` 폴더 업로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 셀 1: 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y sox\n",
    "!pip install -q soundfile librosa tqdm huggingface_hub\n",
    "!pip install flash-attn --no-build-isolation\n",
    "!git clone https://github.com/QwenLM/Qwen3-TTS.git /content/Qwen3-TTS-repo\n",
    "%cd /content/Qwen3-TTS-repo\n",
    "!pip install -e .\n",
    "print(\"환경 설정 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 셀 2: Google Drive 마운트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"드라이브 마운트 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 셀 3: 학습 코드 패치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_path = \"/content/Qwen3-TTS-repo/finetuning/sft_12hz.py\"\n",
    "\n",
    "with open(sft_path, 'r') as f:\n",
    "    code = f.read()\n",
    "\n",
    "code = code.replace('log_with=\"tensorboard\"', 'log_with=None')\n",
    "\n",
    "with open(sft_path, 'w') as f:\n",
    "    f.write(code)\n",
    "\n",
    "print(\"패치 완료! (flash_attention_2 유지)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 셀 4: 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "model_path = snapshot_download(\n",
    "    \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\", \n",
    "    local_dir=\"/content/qwen3_tts_model\"\n",
    ")\n",
    "print(f\"모델 준비 완료: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 셀 5: 마를렌 오디오 변환 + JSONL 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, librosa, soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 마를렌 오디오 24kHz 변환\n",
    "AUDIO_DIR = \"/content/drive/MyDrive/marlene_tts_data/audio\"\n",
    "OUTPUT_DIR = \"/content/audio_24k_marlene\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "files = [f for f in os.listdir(AUDIO_DIR) if f.endswith('.wav')]\n",
    "for f in tqdm(files):\n",
    "    try:\n",
    "        audio, _ = librosa.load(os.path.join(AUDIO_DIR, f), sr=24000)\n",
    "        sf.write(os.path.join(OUTPUT_DIR, f), audio, 24000)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"오디오 변환 완료: {len(os.listdir(OUTPUT_DIR))}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSONL 경로 업데이트\n",
    "with open(\"/content/drive/MyDrive/marlene_tts_data/marlene_finetune.jsonl\", 'r', encoding='utf-8') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "valid_files = set(os.listdir(OUTPUT_DIR))\n",
    "REF_AUDIO = \"/content/audio_24k_marlene/Marlene_airSupply_1_01.wav\"\n",
    "\n",
    "filtered = []\n",
    "for item in data:\n",
    "    filename = item['audio']\n",
    "    if filename in valid_files:\n",
    "        filtered.append({\n",
    "            \"audio\": f\"/content/audio_24k_marlene/{filename}\",\n",
    "            \"text\": item['text'],\n",
    "            \"ref_audio\": REF_AUDIO\n",
    "        })\n",
    "\n",
    "with open(\"/content/marlene_24k.jsonl\", 'w', encoding='utf-8') as f:\n",
    "    for item in filtered:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"JSONL 준비 완료: {len(filtered)}개 샘플\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 셀 6: 데이터 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /content/Qwen3-TTS-repo/finetuning/prepare_data.py \\\n",
    "    --device cuda:0 \\\n",
    "    --tokenizer_model_path Qwen/Qwen3-TTS-Tokenizer-12Hz \\\n",
    "    --input_jsonl /content/marlene_24k.jsonl \\\n",
    "    --output_jsonl /content/marlene_tokenized.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# v6 설정 (batch 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /content/drive/MyDrive/marlene_model_v6\n",
    "!python /content/Qwen3-TTS-repo/finetuning/sft_12hz.py \\\n",
    "    --init_model_path /content/qwen3_tts_model \\\n",
    "    --train_jsonl /content/marlene_tokenized.jsonl \\\n",
    "    --output_model_path /content/drive/MyDrive/marlene_model_v6 \\\n",
    "    --batch_size 8 \\\n",
    "    --lr 1e-6 \\\n",
    "    --num_epochs 5 \\\n",
    "    --speaker_name marlene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# C 설정 (batch 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /content/drive/MyDrive/marlene_model_C\n",
    "!python /content/Qwen3-TTS-repo/finetuning/sft_12hz.py \\\n",
    "    --init_model_path /content/qwen3_tts_model \\\n",
    "    --train_jsonl /content/marlene_tokenized.jsonl \\\n",
    "    --output_model_path /content/drive/MyDrive/marlene_model_C \\\n",
    "    --batch_size 2 \\\n",
    "    --lr 1e-6 \\\n",
    "    --num_epochs 5 \\\n",
    "    --speaker_name marlene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 비교 테스트: v6 vs C vs 제로샷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython.display import Audio, display\n",
    "from qwen_tts import Qwen3TTSModel\n",
    "\n",
    "TEST_TEXTS = [\n",
    "    \"뭐야, 왜 이렇게 늦은 거야?\",\n",
    "    \"드디어 해냈다! 이겼어!\",\n",
    "    \"정말 고마워, 잊지 않을게.\",\n",
    "]\n",
    "\n",
    "# ========== v6 모델 (batch 8) ==========\n",
    "print(\"=\" * 50)\n",
    "print(\"v6 모델 (batch 8)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "tts_v6 = Qwen3TTSModel.from_pretrained(\n",
    "    \"/content/drive/MyDrive/marlene_model_v6/checkpoint-epoch-4\",\n",
    "    device_map=\"cuda:0\",\n",
    "    dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "\n",
    "for i, text in enumerate(TEST_TEXTS):\n",
    "    print(f\"\\n[v6-{i+1}] {text}\")\n",
    "    wavs, sr = tts_v6.generate_custom_voice(text=text, speaker=\"marlene\")\n",
    "    display(Audio(wavs[0], rate=sr))\n",
    "\n",
    "del tts_v6\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== C 모델 (batch 2) ==========\n",
    "print(\"=\" * 50)\n",
    "print(\"C 모델 (batch 2)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "tts_c = Qwen3TTSModel.from_pretrained(\n",
    "    \"/content/drive/MyDrive/marlene_model_C/checkpoint-epoch-4\",\n",
    "    device_map=\"cuda:0\",\n",
    "    dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "\n",
    "for i, text in enumerate(TEST_TEXTS):\n",
    "    print(f\"\\n[C-{i+1}] {text}\")\n",
    "    wavs, sr = tts_c.generate_custom_voice(text=text, speaker=\"marlene\")\n",
    "    display(Audio(wavs[0], rate=sr))\n",
    "\n",
    "del tts_c\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Base 모델 Voice Clone (제로샷) ==========\n",
    "print(\"=\" * 50)\n",
    "print(\"Base 모델 Voice Clone (제로샷)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "base_model = Qwen3TTSModel.from_pretrained(\n",
    "    \"/content/qwen3_tts_model\",\n",
    "    device_map=\"cuda:0\",\n",
    "    dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "\n",
    "ref_audio = \"/content/audio_24k_marlene/Marlene_airSupply_1_01.wav\"\n",
    "ref_text = \"필요한 게 있었으면 좋겠는데\"\n",
    "prompt = base_model.create_voice_clone_prompt(ref_audio=ref_audio, ref_text=ref_text)\n",
    "\n",
    "for i, text in enumerate(TEST_TEXTS):\n",
    "    print(f\"\\n[제로샷-{i+1}] {text}\")\n",
    "    wavs, sr = base_model.generate_voice_clone(text=text, voice_clone_prompt=prompt)\n",
    "    display(Audio(wavs[0], rate=sr))\n",
    "\n",
    "print(\"\\n비교 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 결과 정리\n",
    "\n",
    "| 모델 | 결과 |\n",
    "|------|------|\n",
    "| v6 (batch 8) | |\n",
    "| C (batch 2) | |\n",
    "| 제로샷 | |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
